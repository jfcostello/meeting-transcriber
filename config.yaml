# Folder paths
meeting_recordings_folder: "meeting_recording_queue"
processed_video_folder: "processed_video_files"
processed_audio_folder: "processed_audio_files"
transcripts_folder: "transcripts"
summaries_folder: "summaries"
summary_type_presets_folder: "summary_type_presets"


# Whisper settings
whisper:
  model: "turbo"
  language: "en"  # Set to a specific language code or "auto" for automatic detection
  device: "cuda"    # Options: "auto", "cpu", "cuda"
  batch_size: "auto"  # "auto" or an integer
  use_fp16: "auto"    # "auto", true, or false
  segment_length: "auto"  # "auto" or an integer (seconds)

# You can use 'Anthropic' 'OpenAI' 'Groq' 'gemini' or 'Replicate', any model there will do. You can also use OpenAIs API endpoint for local models
llm:
  model: "gemini-1.5-pro-002"
  client_type: gemini
  max_tokens: 8192
  temperature: 0.2

# Summary settings, give the name of the .txt file but without .txt, eg meetings.txt is "meetings"
summary_type: "meeting" 

# Do you want timestamps in the transcript? If you've no use for them set to false as it will increase your token cost on summarization
add_timestamp: true
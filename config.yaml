# Folder paths
meeting_recordings_folder: "meeting_recording_queue"
processed_video_folder: "processed_video_files"
processed_audio_folder: "processed_audio_files"
transcripts_folder: "transcripts"
summaries_folder: "summaries"
summary_type_presets_folder: "summary_type_presets"


# Whisper settings
whisper:
  model: "medium"
  language: "en"  # Set to a specific language code or "auto" for automatic detection
  device: "cuda"    # Options: "auto", "cpu", "cuda"
  batch_size: "auto"  # "auto" or an integer
  use_fp16: "auto"    # "auto", true, or false
  segment_length: "auto"  # "auto" or an integer (seconds)

# You can use 'Anthropic' 'OpenAI' 'Groq' 'Gemini' or 'Replicate', any model there will do. You can also use OpenAIs API endpoint for local models
llm:
  model: "gpt-4o-2024-08-06"
  client_type: openai
  max_tokens: 4000
  temperature: 0

# Summary settings, give the name of the .txt file but without .txt, eg meetings.txt is "meetings"
summary_type: "meeting" 

# Add this line somewhere appropriate in the config file
add_timestamp: true

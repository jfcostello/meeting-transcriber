# Folder paths
meeting_recordings_folder: "meeting_recording_queue"
processed_video_folder: "processed_video_files"
processed_audio_folder: "processed_audio_files"
transcripts_folder: "transcripts"
summaries_folder: "summaries"
summary_type_presets_folder: "summary_type_presets"

# You can use 'Anthropic' 'OpenAI' 'Groq' 'gemini' or 'Replicate', any model there will do. You can also use OpenAIs API endpoint for local models by setting client_type to local_openai
llm:
  model: "gemini-1.5-pro-002"
  client_type: gemini
  max_tokens: 8192
  temperature: 0.2

# Summary settings, give the name of the .txt file but without .txt, eg meetings.txt is "meetings"
summary_type: "meeting" 

# Setting to modify the name of the file after it processes it to add a timestamp which can keep your outpout folders organized
add_timestamp: true

# Transcription Engine Configuration
transcription_engine: "whisper"  # Options: "whisper", "faster_whisper", faster_whisper can be useful for larger files and/or if you don't have a GPU

# Whisper settings
whisper:
  model: "turbo"
  language: "en"  # Set to a specific language code or "auto" for automatic detection
  device: "cpu"    # Options: "auto", "cpu", "cuda"
  batch_size: "auto"  # "auto" or an integer
  use_fp16: "auto"    # "auto", true, or false
  segment_length: "auto"  # "auto" or an integer (seconds)

# Faster Whisper Settings
faster_whisper:
  model: "small.en"         # Specify the Faster Whisper model size
  device: "auto"           # Options: "auto", "cpu", "cuda"
  compute_type: "auto"  # Options: "auto" "float16", "int8_float16", "int8"
  beam_size: 5             # Beam size for transcription, beam size of 5 is a good default. A higher beam size may improve accuracy but will be slower.